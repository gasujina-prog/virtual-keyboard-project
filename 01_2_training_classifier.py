import torch
import torch.nn as nn
import torch.optim as optim
from torchvision import datasets, transforms
from torch.utils.data import DataLoader, random_split
import os


# ==========================================
# 1. ëª¨ë¸ ì •ì˜ (Batch Normalization ì¶”ê°€)
# ==========================================
class TouchClassifier(nn.Module):
    def __init__(self):
        super(TouchClassifier, self).__init__()
        self.features = nn.Sequential(
            # Block 1
            nn.Conv2d(3, 32, kernel_size=3, padding=1),
            nn.BatchNorm2d(32),  # [ì¶”ê°€] í•™ìŠµ ì•ˆì •í™”
            nn.ReLU(),
            nn.MaxPool2d(2),

            # Block 2
            nn.Conv2d(32, 64, kernel_size=3, padding=1),
            nn.BatchNorm2d(64),  # [ì¶”ê°€]
            nn.ReLU(),
            nn.MaxPool2d(2),

            # Block 3
            nn.Conv2d(64, 128, kernel_size=3, padding=1),
            nn.BatchNorm2d(128),  # [ì¶”ê°€]
            nn.ReLU(),
            nn.MaxPool2d(2),
        )
        self.classifier = nn.Sequential(
            nn.Flatten(),
            nn.Linear(128 * 8 * 8, 256),  # ë‰´ëŸ° ìˆ˜ ì•½ê°„ ì¦ê°€
            nn.ReLU(),
            nn.Dropout(0.5),  # ê³¼ëŒ€ì í•© ë°©ì§€
            nn.Linear(256, 2)  # 0: Hover, 1: Touch
        )

    def forward(self, x):
        x = self.features(x)
        x = self.classifier(x)
        return x


# ==========================================
# 2. í•™ìŠµ ì„¤ì • ë° ì‹¤í–‰
# ==========================================
def train():
    DATA_DIR = "touch_dataset"
    if not os.path.exists(DATA_DIR):
        print("âŒ ë°ì´í„°ì…‹ í´ë”ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return

    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print(f"ğŸš€ í•™ìŠµ ì¥ì¹˜: {device}")

    # â˜… [í•µì‹¬] ë°ì´í„° ì¦ê°• (Augmentation) â˜…
    # í•™ìŠµìš© ë°ì´í„°ì—ëŠ” ë³€í˜•ì„ ì£¼ì–´ ê°•í•˜ê²Œ í‚¤ì›ë‹ˆë‹¤.
    train_transform = transforms.Compose([
        transforms.Resize((64, 64)),
        transforms.RandomHorizontalFlip(p=0.5),  # ì¢Œìš° ë°˜ì „
        transforms.RandomRotation(10),  # ì•½ê°„ íšŒì „ (-10~10ë„)
        transforms.ColorJitter(brightness=0.2, contrast=0.2),  # ë°ê¸°/ëŒ€ë¹„ ë³€í™”
        transforms.ToTensor(),
    ])

    # ê²€ì¦ìš© ë°ì´í„°ëŠ” ë³€í˜• ì—†ì´ ì›ë³¸ ê·¸ëŒ€ë¡œ í‰ê°€í•©ë‹ˆë‹¤.
    val_transform = transforms.Compose([
        transforms.Resize((64, 64)),
        transforms.ToTensor(),
    ])

    # ì „ì²´ ë°ì´í„°ì…‹ ë¡œë“œ
    full_dataset = datasets.ImageFolder(DATA_DIR)  # transformì€ ë‚˜ì¤‘ì— ì ìš©

    # í•™ìŠµ(80%) / ê²€ì¦(20%) ë¶„ë¦¬
    train_size = int(0.8 * len(full_dataset))
    val_size = len(full_dataset) - train_size
    train_data, val_data = random_split(full_dataset, [train_size, val_size])

    # transform ì ìš©ì„ ìœ„í•´ ë˜í¼(Wrapper) ì‚¬ìš© ë˜ëŠ” ë°ì´í„°ì…‹ ë¶„ë¦¬ ë¡œì§ ìˆ˜ì • í•„ìš”
    # ê°„ë‹¨í•˜ê²Œ êµ¬í˜„í•˜ê¸° ìœ„í•´ ì—¬ê¸°ì„œëŠ” ImageFolderë¥¼ ë‘ ë²ˆ ë¶ˆëŸ¬ì„œ split indexë¡œ ë‚˜ëˆ•ë‹ˆë‹¤.
    # (ì‹¤ë¬´ì—ì„œëŠ” Custom Dataset í´ë˜ìŠ¤ë¥¼ ì”ë‹ˆë‹¤)
    train_dataset = datasets.ImageFolder(DATA_DIR, transform=train_transform)
    val_dataset = datasets.ImageFolder(DATA_DIR, transform=val_transform)

    # ì¸ë±ìŠ¤ë¡œ ì„œë¸Œì…‹ ìƒì„±
    train_subset = torch.utils.data.Subset(train_dataset, train_data.indices)
    val_subset = torch.utils.data.Subset(val_dataset, val_data.indices)

    # ë°ì´í„° ë¡œë” (Batch Size: 32 ì¶”ì²œ)
    train_loader = DataLoader(train_subset, batch_size=32, shuffle=True)
    val_loader = DataLoader(val_subset, batch_size=32, shuffle=False)

    print(f"ë°ì´í„° ê°œìˆ˜: í•™ìŠµ {len(train_subset)}ì¥ / ê²€ì¦ {len(val_subset)}ì¥")

    # ëª¨ë¸ & ì„¤ì •
    model = TouchClassifier().to(device)
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=0.001)  # ì´ˆê¸° í•™ìŠµë¥ 

    # í•™ìŠµë¥  ìŠ¤ì¼€ì¤„ëŸ¬ (ì„±ëŠ¥ ì •ì²´ ì‹œ í•™ìŠµë¥  ê°ì†Œ)
    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=3)

    # í•™ìŠµ ë£¨í”„
    EPOCHS = 50  # ì—í¬í¬ ëŠ˜ë¦¼
    best_loss = float('inf')

    print("=== í•™ìŠµ ì‹œì‘ ===")

    for epoch in range(EPOCHS):
        # [í›ˆë ¨ ëª¨ë“œ]
        model.train()
        running_loss = 0.0
        correct = 0
        total = 0

        for inputs, labels in train_loader:
            inputs, labels = inputs.to(device), labels.to(device)

            optimizer.zero_grad()
            outputs = model(inputs)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()

            running_loss += loss.item()
            _, predicted = torch.max(outputs.data, 1)
            total += labels.size(0)
            correct += (predicted == labels).sum().item()

        train_loss = running_loss / len(train_loader)
        train_acc = 100 * correct / total

        # [ê²€ì¦ ëª¨ë“œ]
        model.eval()
        val_loss = 0.0
        val_correct = 0
        val_total = 0

        with torch.no_grad():
            for inputs, labels in val_loader:
                inputs, labels = inputs.to(device), labels.to(device)
                outputs = model(inputs)
                loss = criterion(outputs, labels)

                val_loss += loss.item()
                _, predicted = torch.max(outputs.data, 1)
                val_total += labels.size(0)
                val_correct += (predicted == labels).sum().item()

        val_loss /= len(val_loader)
        val_acc = 100 * val_correct / val_total

        # ìŠ¤ì¼€ì¤„ëŸ¬ ì—…ë°ì´íŠ¸
        scheduler.step(val_loss)

        print(f"Epoch {epoch + 1}/{EPOCHS} | "
              f"Train Loss: {train_loss:.4f} Acc: {train_acc:.2f}% | "
              f"Val Loss: {val_loss:.4f} Acc: {val_acc:.2f}%")

        # ìµœê³  ì„±ëŠ¥ ëª¨ë¸ ì €ì¥ (ê²€ì¦ ì†ì‹¤ ê¸°ì¤€)
        if val_loss < best_loss:
            best_loss = val_loss
            torch.save(model.state_dict(), "touch_classifier_best.pth")
            print("  --> ğŸ’¾ ìµœê³  ëª¨ë¸ ì €ì¥ë¨!")

    print("=== í•™ìŠµ ì™„ë£Œ ===")
    print(f"ìµœì¢… ëª¨ë¸ì€ 'touch_classifier_best.pth'ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")


if __name__ == "__main__":
    train()
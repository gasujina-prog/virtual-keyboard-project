import cv2
import cv2.aruco as aruco
from PIL import Image, ImageDraw, ImageFont
import numpy as np
import json
import time
import pyautogui
from ultralytics import YOLO

# ==========================================
# 1. ì„¤ì • ë° ìƒìˆ˜
# ==========================================
# ë§µí•‘í•  ë•Œ ì‚¬ìš©í–ˆë˜ í•´ìƒë„ì™€ ë™ì¼í•´ì•¼ í•©ë‹ˆë‹¤. (JSON íŒŒì¼ ë§Œë“¤ ë•Œì˜ í•´ìƒë„)
# ë³´ë‚´ì£¼ì‹  JSON ì¢Œí‘œë¥¼ ë³´ë‹ˆ ê°€ë¡œê°€ 1200 ì •ë„ê¹Œì§€ ê°€ëŠ” ê²ƒ ê°™ì•„ 1200x620ìœ¼ë¡œ ë§ì·„ìŠµë‹ˆë‹¤.
WARP_W = 1200
WARP_H = 620
LAYOUT_FILE = "key_layout.json"
MODEL_PATH = R'finger_project\finger_project\train_result\weights\YUN_best.pt'  # ëª¨ë¸ ê²½ë¡œ í™•ì¸ í•„ìˆ˜!

# ì…ë ¥ ì„¤ì •
DWELL_TIME_THRESHOLD = 0.5  # 0.5ì´ˆ ë¨¸ë¬´ë¥´ë©´ ì…ë ¥
COOLDOWN_TIME = 0.3  # ì…ë ¥ í›„ 0.3ì´ˆ ëŒ€ê¸°
MULTI_FINGER_MODE = True  # ì—¬ëŸ¬ ì†ê°€ë½ ë™ì‹œ ì…ë ¥ í—ˆìš©

# pyautogui ì•ˆì „ì¥ì¹˜ (ë§ˆìš°ìŠ¤ê°€ êµ¬ì„ìœ¼ë¡œ ê°€ë©´ ê°•ì œ ì¢…ë£Œ)
pyautogui.FAILSAFE = True

# íŠ¹ìˆ˜ í‚¤ ë§¤í•‘ (JSONì˜ í‚¤ ì´ë¦„ -> pyautogui í‚¤ ì´ë¦„)
SPECIAL_KEYS = {
    "SpaceBar": "space",
    "Enter": "enter",
    "Backspace": "backspace",
    "Tab": "tab",
    "CapsLock": "capslock",
    "Shift": "shift",
    "RShift": "shiftright",
    "Ctrl": "ctrl",
    "RCtrl": "ctrlright",
    "Alt": "alt",
    "RAlt": "altright",
    "Win": "win",
    "í•œ/ì˜": "í•œ/ì˜",  # Fní‚¤ëŠ” OSì—ì„œ ì§ì ‘ ì œì–´í•˜ê¸° ì–´ë ¤ì›€
    "up": "up",
    "down": "down",
    "left": "left",
    "right": "right",
    "Home": "home",
    "End": "end",
    "PageUp": "pageup",
    "PageDown": "pagedown",
    "~": "`",  # ë¬¼ê²°í‘œëŠ” ë°±í‹±ìœ¼ë¡œ ë§¤í•‘
    "\\": "\\"
}

# JSON ë¡œë“œ
try:
    with open(LAYOUT_FILE, "r", encoding="utf-8") as f:
        raw_layout = json.load(f)

    # JSON í¬ë§· ë³€í™˜ (ë¦¬ìŠ¤íŠ¸ -> ë”•ì…”ë„ˆë¦¬)
    # íŒŒì¼ì—ëŠ” "key": [x, y, w, h] ë¡œ ì €ì¥ë˜ì–´ ìˆìŒ
    KEY_LAYOUT = {}
    for k, v in raw_layout.items():
        KEY_LAYOUT[k] = {'x': v[0], 'y': v[1], 'w': v[2], 'h': v[3]}

    print(f"âœ… {LAYOUT_FILE} ë¡œë“œ ì„±ê³µ! í‚¤ ê°œìˆ˜: {len(KEY_LAYOUT)}")
except FileNotFoundError:
    print(f"âŒ {LAYOUT_FILE} íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. ê°™ì€ í´ë”ì— ë„£ì–´ì£¼ì„¸ìš”.")
    exit()

# YOLO ë¡œë“œ
print("ëª¨ë¸ ë¡œë”© ì¤‘...")
model = YOLO(MODEL_PATH)

# AprilTag ì„¤ì •
aruco_dict = aruco.getPredefinedDictionary(aruco.DICT_APRILTAG_25h9)
parameters = aruco.DetectorParameters()


# ==========================================
# 2. ìœ í‹¸ í•¨ìˆ˜ (ë§ˆì»¤ ë¶„ë¥˜ ë° ì¶”ì )
# ==========================================
def classify_four_tags(corners, ids):
    ids = np.array(ids).flatten()
    centers = []
    for i, c in enumerate(corners):
        c_flat = np.array(c).reshape(-1, 2)
        cx, cy = c_flat.mean(axis=0)
        centers.append((i, cx, cy))  # (index, x, y)

    centers = np.array(centers, dtype=float)

    # y ê¸°ì¤€ ì •ë ¬ â†’ ìœ„/ì•„ë˜
    sort_by_y = centers[np.argsort(centers[:, 2])]
    top_two = sort_by_y[:2]
    bottom_two = sort_by_y[2:]

    # ê°ê° x ê¸°ì¤€ ì •ë ¬ â†’ ì¢Œ/ìš°
    top_two = top_two[np.argsort(top_two[:, 1])]
    bottom_two = bottom_two[np.argsort(bottom_two[:, 1])]

    tl_idx = int(top_two[0, 0])
    tr_idx = int(top_two[1, 0])
    bl_idx = int(bottom_two[0, 0])
    br_idx = int(bottom_two[1, 0])

    # â˜… ë°”ê¹¥ìª½ ëª¨ì„œë¦¬ ì„ íƒ ë¡œì§ (ë§µí•‘ ë²”ìœ„ ìµœëŒ€í™”) â˜…
    # AprilTag ì½”ë„ˆ ì¸ë±ìŠ¤: 0=ì¢Œìƒ, 1=ìš°ìƒ, 2=ìš°í•˜, 3=ì¢Œí•˜
    def corner_outer(idx, role):
        c = np.array(corners[idx]).reshape(-1, 2)
        if role == 'TL':
            return c[3]  # ì¢Œìƒë‹¨ì˜ ì¢Œìƒ
        elif role == 'TR':
            return c[2]  # ìš°ìƒë‹¨ì˜ ìš°ìƒ
        elif role == 'BR':
            return c[1]  # ìš°í•˜ë‹¨ì˜ ìš°í•˜
        elif role == 'BL':
            return c[0]  # ì¢Œí•˜ë‹¨ì˜ ì¢Œí•˜
        return c.mean(axis=0)

    return {
        'TL': corner_outer(tl_idx, 'TL'),
        'TR': corner_outer(tr_idx, 'TR'),
        'BL': corner_outer(bl_idx, 'BL'),
        'BR': corner_outer(br_idx, 'BR')
    }


def draw_keyboard_quad(frame, quad, color=(0, 255, 0)):
    quad_int = quad.astype(int)
    for i in range(4):
        cv2.line(frame, tuple(quad_int[i]), tuple(quad_int[(i + 1) % 4]), color, 2)


def draw_keyboard_text_all(img, layout_dict, font_path="malgun.ttf", size=20):
    """
    ì´ë¯¸ì§€ë¥¼ Pillowë¡œ ë³€í™˜í•œ ë’¤, ëª¨ë“  í‚¤ì˜ ê¸€ìë¥¼ í•œ ë²ˆì— ì“°ê³  ë‹¤ì‹œ OpenCV í¬ë§·ìœ¼ë¡œ ë°˜í™˜
    """
    # 1. OpenCV(BGR) -> PIL(RGB) ë³€í™˜ (ë”± í•œ ë²ˆ!)
    img_pil = Image.fromarray(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))
    draw = ImageDraw.Draw(img_pil)

    try:
        font = ImageFont.truetype(font_path, size)
    except:
        font = ImageFont.load_default()

    # 2. ëª¨ë“  í‚¤ì— ëŒ€í•´ ë°˜ë³µí•´ì„œ ê¸€ì”¨ ì“°ê¸° (ë³€í™˜ ì—†ì´ ê·¸ë¦¬ê¸°ë§Œ ë°˜ë³µ)
    for key, rect in layout_dict.items():
        # rect í¬ë§· í™•ì¸ (ë¦¬ìŠ¤íŠ¸ or ë”•ì…”ë„ˆë¦¬)
        if isinstance(rect, dict):
            x, y = rect['x'], rect['y']
        else:
            x, y = rect[0], rect[1]

        # ê¸€ì ìœ„ì¹˜ ì¡ê¸° (ë°•ìŠ¤ ì•ˆìª½)
        draw.text((x + 5, y + 5), key, font=font, fill=(0, 255, 0))  # ê²€ì€ìƒ‰ ê¸€ì”¨

    # 3. PIL(RGB) -> OpenCV(BGR) ë³€í™˜ (ë”± í•œ ë²ˆ!)
    return cv2.cvtColor(np.array(img_pil), cv2.COLOR_RGB2BGR)

# ==========================================
# 3. ìƒíƒœ ë³€ìˆ˜
# ==========================================
prev_homography = None
prev_quad = None
prev_tag_centers = {}

# í‚¤ë³„ ìƒíƒœ ê´€ë¦¬: { 'key_name': { 'start_time': 0.0, 'last_input': 0.0 } }
key_states = {k: {'start_time': 0, 'last_input': 0} for k in KEY_LAYOUT.keys()}

# ==========================================
# 4. ë©”ì¸ ë£¨í”„
# ==========================================
cap = cv2.VideoCapture(0)
if not cap.isOpened(): exit()

print("=== ê°€ìƒ í‚¤ë³´ë“œ ì‹œì‘ (ì¢…ë£Œ: q) ===")

while True:
    ret, frame = cap.read()
    if not ret: break

    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
    corners, ids, _ = aruco.detectMarkers(gray, aruco_dict, parameters=parameters)

    current_homography = None
    warped_view = np.zeros((WARP_H, WARP_W, 3), dtype=np.uint8)

    # [1] ë§ˆì»¤ ì¶”ì  ë° ë³€í™˜ í–‰ë ¬ ê³„ì‚°
    corners_np = []
    if ids is not None:
        ids = ids.flatten()
        corners_np = [np.array(c).reshape(-1, 2) for c in corners]
        # aruco.drawDetectedMarkers(frame, corners, ids.reshape(-1, 1)) # (ì„ íƒ) ë§ˆì»¤ í…Œë‘ë¦¬ ë³´ê¸°

    curr_tag_centers = {}
    if ids is not None:
        for i, tag_id in enumerate(ids):
            curr_tag_centers[int(tag_id)] = corners_np[i].mean(axis=0)

    num_tags = len(ids) if ids is not None else 0
    img_quad = None

    # A. 4ê°œ ë‹¤ ë³´ì„ (ê¸°ì¤€ ê°±ì‹ )
    if num_tags >= 4:
        roles = classify_four_tags(corners_np, ids)
        src_pts = np.array([roles['BR'], roles['BL'], roles['TL'], roles['TR']], dtype=np.float32)
        dst_pts = np.array([[0, 0], [WARP_W, 0], [WARP_W, WARP_H], [0, WARP_H]], dtype=np.float32)

        H = cv2.getPerspectiveTransform(src_pts, dst_pts)
        current_homography = H

        prev_homography = H.copy()
        prev_tag_centers = curr_tag_centers.copy()
        img_quad = src_pts.copy()
        prev_quad = img_quad.copy()

    # B. 3ê°œ ì´í•˜ (ì¶”ì )
    elif num_tags >= 2 and prev_homography is not None:
        common_ids = []
        src_prev, src_curr = [], []
        for tid in curr_tag_centers:
            if tid in prev_tag_centers:
                common_ids.append(tid)
                src_prev.append(prev_tag_centers[tid])
                src_curr.append(curr_tag_centers[tid])

        if len(common_ids) >= 2:
            src_prev = np.array(src_prev).reshape(-1, 1, 2)
            src_curr = np.array(src_curr).reshape(-1, 1, 2)
            M, _ = cv2.estimateAffinePartial2D(src_prev, src_curr)

            if M is not None:
                M_homo = np.eye(3)
                M_homo[:2] = M
                prev_quad_h = np.hstack([prev_quad, np.ones((4, 1))])
                curr_quad = (prev_quad_h @ M_homo.T)[:, :2].astype(np.float32)

                dst_pts = np.array([[0, 0], [WARP_W, 0], [WARP_W, WARP_H], [0, WARP_H]], dtype=np.float32)
                current_homography = cv2.getPerspectiveTransform(curr_quad, dst_pts)
                img_quad = curr_quad

    # C. ì¶”ì  ì‹¤íŒ¨ (ìœ ì§€)
    if current_homography is None and prev_homography is not None:
        current_homography = prev_homography
        img_quad = prev_quad

    if img_quad is not None:
        draw_keyboard_quad(frame, img_quad)

    # [2] ê°€ìƒ í™”ë©´ ìƒì„± (í‚¤ë³´ë“œ ê·¸ë¦¬ê¸°)
    if current_homography is not None:
        # ì›Œí•‘ëœ í™”ë©´ì€ ê²€ì€ ë°°ê²½ìœ¼ë¡œ ì‹œì‘ (ë¦¬ì†ŒìŠ¤ ì ˆì•½)
        # í‚¤ë³´ë“œ ë ˆì´ì•„ì›ƒ ê·¸ë¦¬ê¸°
        # 1. ë¨¼ì € ë°•ìŠ¤(ì‚¬ê°í˜•)ë§Œ OpenCVë¡œ ë¹ ë¥´ê²Œ ë‹¤ ê·¸ë¦½ë‹ˆë‹¤.
        for key, rect in KEY_LAYOUT.items():
            if isinstance(rect, dict):
                rx, ry, rw, rh = rect['x'], rect['y'], rect['w'], rect['h']
            else:
                rx, ry, rw, rh = rect
            # ë°•ìŠ¤ ê·¸ë¦¬ê¸° (OpenCVê°€ ë” ë¹ ë¦„)
            cv2.rectangle(warped_view, (rx, ry), (rx + rw, ry + rh), (0, 255, 0), 2)
        # 2. ê¸€ì”¨ëŠ” í•œë°©ì— ëª°ì•„ì„œ ê·¸ë¦½ë‹ˆë‹¤. (ë³€í™˜ ë¹„ìš© ìµœì†Œí™”)
        warped_view = draw_keyboard_text_all(warped_view, KEY_LAYOUT)

    # [3] YOLO ì†ê°€ë½ íƒì§€
    results = model(frame, verbose=False)
    fingers = []
    for r in results:
        for box in r.boxes:
            # box.clsë¥¼ í™•ì¸í•˜ì—¬ ì†ê°€ë½(1ë²ˆ)ì¸ì§€ ì²´í¬í•˜ëŠ” ê²ƒì´ ì¢‹ìŒ (í˜„ì¬ëŠ” ëª¨ë“  ê°ì²´)
            x1, y1, x2, y2 = map(int, box.xyxy[0])

            # ì†ê°€ë½ ë ì¢Œí‘œ ì¶”ì • (ë°•ìŠ¤ í•˜ë‹¨ ì¤‘ì•™)
            # ì—„ì§€/ê²€ì§€ êµ¬ë¶„ì´ ìˆë‹¤ë©´ ì—¬ê¸°ì„œ ì²˜ë¦¬ ê°€ëŠ¥
            fx = (x1 + x2) / 2
            fy = (y1 - y2) / 3 + y2
            fingers.append((fx, fy))

            # ì›ë³¸ í™”ë©´ í‘œì‹œ
            cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 255), 1)
            cv2.circle(frame, (int(fx), int(fy)), 5, (0, 0, 255), -1)

    # [4] ì¢Œí‘œ ë³€í™˜ ë° í‚¤ ì…ë ¥
    if current_homography is not None and fingers:
        # ì¢Œí‘œ ë³€í™˜
        fingers_np = np.array([fingers], dtype=np.float32).transpose(1, 0, 2)
        transformed_fingers = cv2.perspectiveTransform(fingers_np, current_homography)

        active_keys = set()
        curr_time = time.time()

        for pt in transformed_fingers:
            tx, ty = pt[0]

            # ê°€ìƒ í™”ë©´ì— ì†ê°€ë½ í‘œì‹œ
            cv2.circle(warped_view, (int(tx), int(ty)), 8, (0, 0, 255), -1)

            # íˆíŠ¸ í…ŒìŠ¤íŠ¸
            # ---------------------------------------------------------
            # [ìˆ˜ì •] 1. OpenCVë¡œ ë°•ìŠ¤(Rectangle) ë¨¼ì € ê·¸ë¦¬ê¸° (ë¹ ë¦„)
            # ---------------------------------------------------------
            for key_name, rect in KEY_LAYOUT.items():
                rx, ry, rw, rh = rect['x'], rect['y'], rect['w'], rect['h']

                # ê¸°ë³¸ ìŠ¤íƒ€ì¼ (ì•ˆ ëˆŒë¦¼)
                color = (0, 255, 0)  # ì´ˆë¡ìƒ‰
                thickness = 1

                # íˆíŠ¸ í…ŒìŠ¤íŠ¸ (ì†ê°€ë½ì´ í‚¤ ì•ˆì— ìˆëŠ”ì§€ í™•ì¸)
                if rx < tx < rx + rw and ry < ty < ry + rh:
                    active_keys.add(key_name)
                    color = (0, 255, 255)  # ë…¸ë€ìƒ‰ (ëˆŒë¦¼)
                    thickness = -1  # ì±„ìš°ê¸°

                # ë°•ìŠ¤ ê·¸ë¦¬ê¸°
                cv2.rectangle(warped_view, (rx, ry), (rx + rw, ry + rh), color, thickness)

            # ---------------------------------------------------------
            # [ìˆ˜ì •] 2. Pillowë¡œ ê¸€ì”¨(Text) í•œ ë²ˆì— ì“°ê¸° (í•œê¸€/íŠ¹ìˆ˜ë¬¸ì ì§€ì›)
            # ---------------------------------------------------------
            # (1) OpenCV(BGR) -> Pillow(RGB) ë³€í™˜
            img_pil = Image.fromarray(cv2.cvtColor(warped_view, cv2.COLOR_BGR2RGB))
            draw = ImageDraw.Draw(img_pil)

            # í°íŠ¸ ì„¤ì • (ì—†ìœ¼ë©´ ê¸°ë³¸ í°íŠ¸)
            try:
                font = ImageFont.truetype("malgun.ttf", 20)  # ìœˆë„ìš° ë§‘ì€ ê³ ë”•
            except:
                font = ImageFont.load_default()

            # (2) ëª¨ë“  í‚¤ì˜ ê¸€ì”¨ ì“°ê¸°
            for key_name, rect in KEY_LAYOUT.items():
                rx, ry = rect['x'], rect['y']
                # ê¸€ì”¨ ìƒ‰ìƒ (ê²€ì •)
                draw.text((rx + 5, ry + 20), key_name, font=font, fill=(0, 0, 0))

            # (3) Pillow(RGB) -> OpenCV(BGR) ë³µêµ¬
            warped_view = cv2.cvtColor(np.array(img_pil), cv2.COLOR_RGB2BGR)
        # ì…ë ¥ ë¡œì§ (ìƒíƒœ ë¨¸ì‹ )
        for key in active_keys:
            state = key_states[key]

            # ì²˜ìŒ ëˆŒë¦¼
            if state['start_time'] == 0:
                state['start_time'] = curr_time

            # ì²´ë¥˜ ì‹œê°„
            duration = curr_time - state['start_time']

            # ì…ë ¥ í™•ì •
            if duration > DWELL_TIME_THRESHOLD:
                if curr_time - state['last_input'] > COOLDOWN_TIME:
                    print(f"ğŸ‘‰ Press: {key}")

                    # íŠ¹ìˆ˜ í‚¤ ì²˜ë¦¬
                    py_key = SPECIAL_KEYS.get(key, key.lower())

                    if py_key:  # Noneì´ ì•„ë‹ˆë©´ ì…ë ¥
                        try:
                            pyautogui.press(py_key)
                        except:
                            print(f"ì…ë ¥ ë¶ˆê°€ í‚¤: {key}")

                    state['last_input'] = curr_time
                    # ì—°íƒ€ ë°©ì§€ë¥¼ ìœ„í•´ start_timeì€ ìœ ì§€í•˜ì§€ ì•Šê³  ë¦¬ì…‹í•˜ë ¤ë©´ ì•„ë˜ ì£¼ì„ í•´ì œ
                    state['start_time'] = 0

                    # ì…ë ¥ í”¼ë“œë°± (ë¹¨ê°„ìƒ‰)
                    rx, ry, rw, rh = KEY_LAYOUT[key]['x'], KEY_LAYOUT[key]['y'], KEY_LAYOUT[key]['w'], KEY_LAYOUT[key][
                        'h']
                    cv2.rectangle(warped_view, (rx, ry), (rx + rw, ry + rh), (0, 0, 255), -1)

        # ì•ˆ ëˆŒë¦° í‚¤ ë¦¬ì…‹
        for key in KEY_LAYOUT:
            if key not in active_keys:
                key_states[key]['start_time'] = 0

    # [5] í™”ë©´ ì¶œë ¥
    cv2.imshow("Tracking Cam", frame)
    cv2.imshow("Virtual Keyboard", warped_view)

    if cv2.waitKey(1) & 0xFF == ord('q'):
        break

cap.release()
cv2.destroyAllWindows()
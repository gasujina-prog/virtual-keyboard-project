import cv2
import cv2.aruco as aruco
import numpy as np
import time
import torch
import sys
import os
import collections
import pyautogui
from ultralytics import YOLO
import json

# ë¼ì´ë¸ŒëŸ¬ë¦¬ ê²½ë¡œ ê°•ì œ ì¶”ê°€
current_dir = os.path.dirname(os.path.abspath(__file__))
src_path = os.path.join(current_dir, 'src')
sys.path.append(src_path)

from depth_anything_3.api import DepthAnything3

# ==========================================
# 1. ì„¤ì • (Configuration)
# ==========================================
WARP_W = 840
WARP_H = 560
LAYOUT_FILE = "key_layout.json"
YOLO_PATH = r'finger_project/finger_project/train_result/weights/YUN_best.pt'
DA3_MODEL_ID = "depth-anything/DA3-Small"

# ----------------------------------
# [íŠœë‹ íŒŒë¼ë¯¸í„° - ê°ë„ ì¡°ì ˆ í•µì‹¬]
# ----------------------------------
# 1. ê¹Šì´ ê´€ë ¨
DEPTH_HISTORY_LEN = 5  # ì´ë™ í‰ê· ì„ êµ¬í•  í”„ë ˆì„ ìˆ˜ (í´ìˆ˜ë¡ ì•ˆì •ì , ë°˜ì‘ ëŠë¦¼)
TOUCH_DEPTH_DIFF = 15  # (í‰ê·  - í˜„ì¬) ì°¨ì´ê°€ ì´ë³´ë‹¤ í¬ë©´ 'í„°ì¹˜' (ì‘¥ ë‚´ë ¤ê°)
RELEASE_DEPTH_DIFF = 10  # ì°¨ì´ê°€ ì´ë³´ë‹¤ ì‘ì•„ì§€ë©´ 'ë•œ' (ë‹¤ì‹œ ì˜¬ë¼ì˜´)

# 2. ì†ë„ ê´€ë ¨
STOP_SPEED_THRESHOLD = 80.0  # ì´ ì†ë„(px/s)ë³´ë‹¤ ë¹ ë¥´ë©´ í„°ì¹˜ ì¸ì • ì•ˆ í•¨ (ì´ë™ ì¤‘ ì˜¤íƒ€ ë°©ì§€)

# 3. ì…ë ¥ ì¿¨ë‹¤ìš´
COOLDOWN_TIME = 0.1
# ----------------------------------

# íŠ¹ìˆ˜ í‚¤ ë§¤í•‘
SPECIAL_KEYS = {
    "SpaceBar": "space", "Enter": "enter", "Backspace": "backspace",
    "Tab": "tab", "CapsRock": "capslock", "Shift": "shift",
    "RShift": "shiftright", "Ctrl": "ctrl", "Win": "win",
    "Alt": "alt", "up": "up", "down": "down",
    "left": "left", "right": "right", "~": "`"
}

# ==========================================
# 2. ì´ˆê¸°í™”
# ==========================================
# JSON ë¡œë“œ
try:
    with open(LAYOUT_FILE, "r", encoding='utf-8') as f:
        raw_layout = json.load(f)
    KEY_LAYOUT = {}
    for k, v in raw_layout.items():
        KEY_LAYOUT[k] = {'x': v[0], 'y': v[1], 'w': v[2], 'h': v[3]}
except FileNotFoundError:
    print("âŒ key_layout.json íŒŒì¼ ì—†ìŒ")
    exit()

# ë””ë°”ì´ìŠ¤ ì„¤ì •
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"ğŸš€ ì‹¤í–‰ ë””ë°”ì´ìŠ¤: {device}")

# ëª¨ë¸ ë¡œë“œ
yolo_model = YOLO(YOLO_PATH)
try:
    da3_model = DepthAnything3.from_pretrained(DA3_MODEL_ID).to(device).eval()
except Exception as e:
    print(f"DA3 ë¡œë“œ ì‹¤íŒ¨: {e}")
    exit()

# ArUco ì„¤ì •
aruco_dict = aruco.getPredefinedDictionary(aruco.DICT_APRILTAG_25h9)
parameters = aruco.DetectorParameters()

cap = cv2.VideoCapture(0)
if not cap.isOpened(): exit()

# ==========================================
# 3. ìƒíƒœ ë³€ìˆ˜ (ì†ê°€ë½ë³„ ë°ì´í„°)
# ==========================================
# êµ¬ì¡°: { track_id : { 'history': deque, 'prev_pos': (x,y), 'prev_time': t, 'state': 'hover'/'touch' } }
fingers_state = {}

print("=== ìµœì¢… í•˜ì´ë¸Œë¦¬ë“œ í‚¤ë³´ë“œ ì‹œìŠ¤í…œ ì‹œì‘ (ì¢…ë£Œ: q) ===")

while True:
    ret, frame = cap.read()
    if not ret: break

    # ----------------------------------------------------
    # [1] í™˜ê²½ ì¸ì‹ (ë§ˆì»¤ & Depth Map ìƒì„±)
    # ----------------------------------------------------
    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
    corners, ids, _ = aruco.detectMarkers(gray, aruco_dict, parameters=parameters)

    matrix = None
    warped_view = np.zeros((WARP_H, WARP_W, 3), dtype=np.uint8)
    depth_uint8 = None

    if ids is not None and len(ids) >= 4:
        ids = ids.flatten()
        corners_map = {id: corner for id, corner in zip(ids, corners)}

        if all(i in corners_map for i in [0, 1, 2, 3]):
            try:
                # ì¢Œí‘œ ìˆœì„œ: TL(0), TR(1), BR(3), BL(2) (ì‚¬ìš©ì ë§ˆì»¤ ë°°ì¹˜ ê¸°ì¤€)
                src_pts = np.array([
                    corners_map[0][0][1], corners_map[1][0][0],
                    corners_map[3][0][3], corners_map[2][0][2]
                ], dtype=np.float32)
                dst_pts = np.array([
                    [0, 0], [WARP_W, 0], [WARP_W, WARP_H], [0, WARP_H]
                ], dtype=np.float32)

                matrix = cv2.getPerspectiveTransform(src_pts, dst_pts)

                # DA3ìš© ì›Œí•‘ ì´ë¯¸ì§€
                warped_img_da3 = cv2.warpPerspective(frame, matrix, (WARP_W, WARP_H))

                # DA3 ì¶”ë¡  (ê°€ìƒ í™”ë©´ ì „ì²´)
                da3_res = da3_model.inference([warped_img_da3])
                depth_map = da3_res.depth[0]

                # ì •ê·œí™” (0~255)
                d_min, d_max = depth_map.min(), depth_map.max()
                depth_norm = (depth_map - d_min) / (d_max - d_min)
                depth_uint8 = (depth_norm * 255).astype(np.uint8)

                # ë¦¬ì‚¬ì´ì¦ˆ (í˜¹ì‹œ í¬ê¸° ë‹¤ë¥¼ ê²½ìš°)
                if depth_uint8.shape[:2] != (WARP_H, WARP_W):
                    depth_uint8 = cv2.resize(depth_uint8, (WARP_W, WARP_H))

                aruco.drawDetectedMarkers(frame, corners, ids)
            except:
                pass

    # ê°€ìƒ í‚¤ë³´ë“œ ê·¸ë¦¬ê¸°
    for key_name, rect in KEY_LAYOUT.items():
        rx, ry, rw, rh = rect['x'], rect['y'], rect['w'], rect['h']
        cv2.rectangle(warped_view, (rx, ry), (rx + rw, ry + rh), (0, 100, 0), 1)
        cv2.putText(warped_view, key_name, (rx + 5, ry + 20), cv2.FONT_HERSHEY_SIMPLEX, 0.4, (200, 200, 200), 1)

    # ----------------------------------------------------
    # [2] ì†ê°€ë½ ì¶”ì  ë° ìƒíƒœ ì—…ë°ì´íŠ¸
    # ----------------------------------------------------
    # YOLO ì¶”ì  (GPU)
    results = yolo_model.track(frame, persist=True, verbose=False, device=device)
    curr_time = time.time()
    current_ids = set()

    for r in results:
        if r.boxes.id is None: continue
        boxes = r.boxes.xyxy.cpu().numpy()
        track_ids = r.boxes.id.int().cpu().numpy()

        for box, track_id in zip(boxes, track_ids):
            current_ids.add(track_id)

            # [2-1] ìƒíƒœ ì´ˆê¸°í™” (ìƒˆë¡œìš´ ì†ê°€ë½)
            if track_id not in fingers_state:
                fingers_state[track_id] = {
                    'history': collections.deque(maxlen=DEPTH_HISTORY_LEN),  # ê¹Šì´ ê¸°ë¡ (í)
                    'prev_pos': None,
                    'prev_time': 0,
                    'state': 'hover',  # í˜„ì¬ ìƒíƒœ: hover(ëœ¸) / touch(ëˆ„ë¦„)
                    'last_input': 0
                }

            st = fingers_state[track_id]

            # ì¢Œí‘œ ì¶”ì¶œ (ë°•ìŠ¤ í•˜ë‹¨)
            x1, y1, x2, y2 = map(int, box)
            fx = (x1 + x2) / 2
            fy = (y1 - y2) / 3 + y2

            # ì›ë³¸ í™”ë©´ í‘œì‹œ
            cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 255), 2)
            cv2.putText(frame, f"ID:{track_id}", (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 255), 1)

            # [2-2] ë°ì´í„° ê³„ì‚° (ì¢Œí‘œ ë³€í™˜ -> ì†ë„/ê¹Šì´)
            if matrix is not None and depth_uint8 is not None:
                # ì¢Œí‘œ ë³€í™˜
                pts = np.array([[[fx, fy]]], dtype=np.float32)
                trans = cv2.perspectiveTransform(pts, matrix)
                tx, ty = trans[0][0]

                # ë²”ìœ„ ì²´í¬
                if 0 <= tx < WARP_W and 0 <= ty < WARP_H:
                    # A. í˜„ì¬ ê¹Šì´ê°’ (DA3)
                    curr_z = int(depth_uint8[int(ty), int(tx)])

                    # B. íˆìŠ¤í† ë¦¬ ì—…ë°ì´íŠ¸ (í„°ì¹˜ ì¤‘ì´ ì•„ë‹ ë•Œë§Œ ì—…ë°ì´íŠ¸í•˜ê±°ë‚˜, ì²œì²œíˆ ì—…ë°ì´íŠ¸)
                    # ì—¬ê¸°ì„œëŠ” í•­ìƒ ì—…ë°ì´íŠ¸í•˜ë˜, í„°ì¹˜ íŒë‹¨ì€ 'í‰ê· 'ê³¼ ë¹„êµí•¨
                    st['history'].append(curr_z)
                    avg_z = int(np.mean(st['history']))

                    # C. ê¹Šì´ ë³€í™”ëŸ‰ (í‰ê·  - í˜„ì¬)
                    # ì†ê°€ë½ì´ ë‚´ë ¤ê°€ë©´ curr_zê°€ ì‘ì•„ì§ (ì–´ë‘ì›Œì§) -> diffê°€ ì»¤ì§ (+)
                    # (DA3 íŠ¹ì„±: ê°€ê¹Œì›€=ë°ìŒ/í¼, ë©ˆ=ì–´ë‘ì›€/ì‘ìŒ)
                    # ë§Œì•½ ì†ê°€ë½ì´ ë‚´ë ¤ê°ˆ ë•Œ ê°’ì´ ì»¤ì§€ëŠ” ëª¨ë¸ì´ë¼ë©´ ë°˜ëŒ€ë¡œ ê³„ì‚°í•´ì•¼ í•¨
                    # ì¼ë°˜ì ìœ¼ë¡œ: ë°”ë‹¥(ì–´ë‘ì›€) < ì†(ë°ìŒ). ì†ì´ ë°”ë‹¥ìœ¼ë¡œ ê°€ë©´ ì–´ë‘ì›Œì§.
                    # ì¦‰, ë‚´ë ¤ê°ˆ ë•Œ ê°’ ê°ì†Œ -> (í‰ê·  - í˜„ì¬) > 0
                    depth_diff = avg_z - curr_z

                    # D. ì†ë„ ê³„ì‚°
                    speed = 9999.0
                    if st['prev_pos'] is not None and st['prev_time'] > 0:
                        dt = curr_time - st['prev_time']
                        if dt > 0:
                            dist = np.linalg.norm(np.array([tx, ty]) - np.array(st['prev_pos']))
                            speed = dist / dt

                    # ì‹œê°í™”
                    color = (0, 0, 255) if st['state'] == 'hover' else (0, 255, 0)
                    cv2.circle(warped_view, (int(tx), int(ty)), 8, color, -1)
                    cv2.putText(warped_view, f"Diff:{depth_diff} Spd:{int(speed)}",
                                (int(tx), int(ty) - 15), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)

                    # [2-3] í‚¤ íˆíŠ¸ í…ŒìŠ¤íŠ¸
                    detected_key = None
                    for key_name, rect in KEY_LAYOUT.items():
                        rx, ry, rw, rh = rect['x'], rect['y'], rect['w'], rect['h']
                        if rx < tx < rx + rw and ry < ty < ry + rh:
                            detected_key = key_name
                            break

                    # ==================================================
                    # â˜… [í•µì‹¬] ìƒíƒœ ë¨¸ì‹  (State Machine) ë¡œì§ â˜…
                    # ==================================================

                    # 1. í„°ì¹˜ ê°ì§€ (Hover -> Touch)
                    if st['state'] == 'hover':
                        # ì¡°ê±´: í‚¤ ìœ„ì— ìˆìŒ AND ì†ë„ê°€ ì•ˆì •ë¨ AND ê¹Šì´ê°€ ì‘¥ ë“¤ì–´ê°
                        if detected_key and speed < STOP_SPEED_THRESHOLD and depth_diff > TOUCH_DEPTH_DIFF:

                            if (curr_time - st['last_input']) > COOLDOWN_TIME:
                                print(f"ğŸ‘‰ Touch(ID:{track_id}): {detected_key} (Diff:{depth_diff})")

                                # ì…ë ¥ ì‹¤í–‰
                                py_key = SPECIAL_KEYS.get(detected_key, detected_key.lower())
                                if py_key: pyautogui.press(py_key)

                                # ìƒíƒœ ë³€ê²½ ë° ì¿¨ë‹¤ìš´
                                st['state'] = 'touch'
                                st['last_input'] = curr_time

                                # ì‹œê° íš¨ê³¼
                                rx, ry, rw, rh = KEY_LAYOUT[detected_key]['x'], KEY_LAYOUT[detected_key]['y'], \
                                KEY_LAYOUT[detected_key]['w'], KEY_LAYOUT[detected_key]['h']
                                cv2.rectangle(warped_view, (rx, ry), (rx + rw, ry + rh), (0, 0, 255), -1)

                    # 2. ë¦´ë¦¬ì¦ˆ ê°ì§€ (Touch -> Hover)
                    elif st['state'] == 'touch':
                        # ì¡°ê±´: ê¹Šì´ ì°¨ì´ê°€ ì¤„ì–´ë“¤ë©´ (ë‹¤ì‹œ ì˜¬ë¼ì˜¤ë©´) í•´ì œ
                        if depth_diff < RELEASE_DEPTH_DIFF:
                            st['state'] = 'hover'
                            print(f"ğŸ’¨ Release(ID:{track_id})")

                    # ìƒíƒœ ì—…ë°ì´íŠ¸
                    st['prev_pos'] = (tx, ty)
                    st['prev_time'] = curr_time

    # ì‚¬ë¼ì§„ ID ì •ë¦¬
    expired_ids = [k for k in fingers_state.keys() if k not in current_ids]
    for k in expired_ids: del fingers_state[k]

    # í™”ë©´ ì¶œë ¥
    cv2.imshow("Tracking Cam", frame)
    cv2.imshow("Hybrid Keyboard", warped_view)

    if cv2.waitKey(1) & 0xFF == ord('q'):
        break

cap.release()
cv2.destroyAllWindows()
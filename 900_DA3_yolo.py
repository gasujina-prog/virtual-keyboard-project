import cv2
import cv2.aruco as aruco
import numpy as np
import time
import torch
import sys
import os
from ultralytics import YOLO

# ë¼ì´ë¸ŒëŸ¬ë¦¬ ê²½ë¡œ ê°•ì œ ì¶”ê°€ (ì„¤ì¹˜ ë¬¸ì œ ëŒ€ë¹„)
current_dir = os.path.dirname(os.path.abspath(__file__))
src_path = os.path.join(current_dir, 'src')
sys.path.append(src_path)

from depth_anything_3.api import DepthAnything3

# ==========================================
# 1. ì„¤ì • (Configuration)
# ==========================================
# ê°€ìƒ A4 í‰ë©´ í•´ìƒë„ (DA3 ì…ë ¥ìš©ìœ¼ë¡œ ë„ˆë¬´ í¬ì§€ ì•Šê²Œ ì„¤ì •)
WARP_W = 518
WARP_H = 732  # A4 ë¹„ìœ¨ (1:1.414)

# ëª¨ë¸ ì„¤ì •
YOLO_PATH = 'finger_project/finger_project/train_result/weights/best.pt'
DA3_MODEL_ID = "depth-anything/DA3-base"  # ë˜ëŠ” ë¡œì»¬ .pth íŒŒì¼ ê²½ë¡œ

# í„°ì¹˜ ê°ë„ ì„¤ì • (ì¤‘ìš”!)
# (ì†ê°€ë½ ê¹Šì´ - ì¢…ì´ ê¹Šì´) ì°¨ì´ê°€ ì´ ê°’ë³´ë‹¤ ì‘ìœ¼ë©´ 'í„°ì¹˜'ë¡œ ì¸ì •
# DA3 ì¶œë ¥ì€ ìƒëŒ€ê°’ì´ë¯€ë¡œ í…ŒìŠ¤íŠ¸í•˜ë©° ì¡°ì ˆ í•„ìš” (ë³´í†µ 0.05 ~ 0.1 ì‚¬ì´)
TOUCH_THRESHOLD = 0.5

# ==========================================
# 2. ì´ˆê¸°í™”
# ==========================================
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"ğŸš€ ë””ë°”ì´ìŠ¤: {device}")

# ëª¨ë¸ ë¡œë“œ
yolo_model = YOLO(YOLO_PATH)
try:
    da3_model = DepthAnything3.from_pretrained(DA3_MODEL_ID).to(device).eval()
except Exception as e:
    print(f"DA3 ë¡œë“œ ì‹¤íŒ¨: {e}")
    exit()

# ArUco ì„¤ì •
aruco_dict = aruco.getPredefinedDictionary(aruco.DICT_APRILTAG_25h9)
parameters = aruco.DetectorParameters()

# ì¹´ë©”ë¼ ì—°ê²°
cap = cv2.VideoCapture(0)
if not cap.isOpened(): exit()


# ==========================================
# 3. ìœ í‹¸ í•¨ìˆ˜
# ==========================================
def get_perspective_matrix(frame, corners, ids):
    # (ì´ì „ ì½”ë“œì™€ ë™ì¼í•œ ë§ˆì»¤ ì •ë ¬ ë° Matrix ê³„ì‚° ë¡œì§)
    ids = ids.flatten()
    corners_map = {id: corner for id, corner in zip(ids, corners)}

    # 0:TL, 1:TR, 3:BR, 2:BL (ì‚¬ìš©ì ë§ˆì»¤ ë°°ì¹˜ ê¸°ì¤€)
    if not all(i in corners_map for i in [0, 1, 2, 3]):
        return None

    # ë°”ê¹¥ìª½ ëª¨ì„œë¦¬ ê¸°ì¤€ (ìµœëŒ€ ì˜ì—­)
    pt_tl = corners_map[0][0][0]
    pt_tr = corners_map[1][0][1]
    pt_br = corners_map[3][0][2]
    pt_bl = corners_map[2][0][3]

    src_pts = np.array([pt_tl, pt_tr, pt_br, pt_bl], dtype=np.float32)
    dst_pts = np.array([[0, 0], [WARP_W, 0], [WARP_W, WARP_H], [0, WARP_H]], dtype=np.float32)

    return cv2.getPerspectiveTransform(src_pts, dst_pts)


print("=== ì‹œìŠ¤í…œ ì‹œì‘ (ì¢…ë£Œ: q) ===")

while True:
    ret, frame = cap.read()
    if not ret: break

    # 1. ë§ˆì»¤ íƒì§€ ë° Warped View ìƒì„±
    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
    corners, ids, _ = aruco.detectMarkers(gray, aruco_dict, parameters=parameters)

    matrix = None
    warped_view = None
    depth_map = None

    if ids is not None and len(ids) >= 4:
        matrix = get_perspective_matrix(frame, corners, ids)

        if matrix is not None:
            # [í•µì‹¬ 1] ë§ˆì»¤ ì˜ì—­ë§Œ ì˜ë¼ì„œ ì •ë©´ ë·°ë¡œ ë§Œë“¦
            warped_view = cv2.warpPerspective(frame, matrix, (WARP_W, WARP_H))

            # [í•µì‹¬ 2] ì˜ë¼ë‚¸ ì˜ì—­(ì¢…ì´)ë§Œ DA3ë¡œ ê¹Šì´ ì¶”ì •
            # (ì „ì²´ í™”ë©´ë³´ë‹¤ ì‘ì•„ì„œ ë¹ ë¥´ê³ , ì¢…ì´ ìœ„ ë¬¼ì²´ ë¶„ì„ì— ìµœì í™”ë¨)
            try:
                da3_res = da3_model.inference([warped_view])
                depth_map = da3_res.depth[0]  # (WARP_H, WARP_W)

                # ê¹Šì´ ì •ê·œí™” (0~1) : ë¹„êµë¥¼ ìœ„í•´ í•„ìˆ˜
                d_min, d_max = depth_map.min(), depth_map.max()
                depth_norm = (depth_map - d_min) / (d_max - d_min)
                print(f" - ìµœì†Œê°’: {depth_map.min():.4f} (ë©€ë‹¤)")
                print(f" - ìµœëŒ€ê°’: {depth_map.max():.4f} (ê°€ê¹ë‹¤)")

            except Exception as e:
                print(e)

    # 2. YOLO ì†ê°€ë½ íƒì§€ (ì›ë³¸ í”„ë ˆì„ì—ì„œ)
    yolo_results = yolo_model(frame, verbose=False)

    for r in yolo_results:
        for box in r.boxes:
            # ì†ê°€ë½ ì¢Œí‘œ (ì›ë³¸)
            x1, y1, x2, y2 = map(int, box.xyxy[0])
            fx, fy = (x1 + x2) / 2, y2  # ì†ê°€ë½ ë

            # ì‹œê°í™” (ì›ë³¸)
            cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 255), 2)

            # 3. ì¢Œí‘œ ë³€í™˜ ë° ê¹Šì´ ë¹„êµ
            if matrix is not None and depth_map is not None:
                # ì†ê°€ë½ ì¢Œí‘œë¥¼ Warped View ì¢Œí‘œë¡œ ë³€í™˜
                pts = np.array([[[fx, fy]]], dtype=np.float32)
                transformed = cv2.perspectiveTransform(pts, matrix)
                tx, ty = map(int, transformed[0][0])

                # ë²”ìœ„ ì²´í¬
                if 0 <= tx < WARP_W and 0 <= ty < WARP_H:
                    # [í•µì‹¬ 3] ì†ê°€ë½ ë°•ìŠ¤ ë¶€ë¶„ì˜ ê¹Šì´ vs ì¢…ì´ ê¹Šì´ ë¹„êµ
                    # ì†ê°€ë½ ë ì£¼ë³€(ROI)ì˜ ê¹Šì´ê°’ì„ ê°€ì ¸ì˜´ (ì˜ˆ: 10x10 ì˜ì—­)
                    roi_size = 5
                    roi_y1, roi_y2 = max(0, ty - roi_size), min(WARP_H, ty + roi_size)
                    roi_x1, roi_x2 = max(0, tx - roi_size), min(WARP_W, tx + roi_size)

                    finger_depth_roi = depth_norm[roi_y1:roi_y2, roi_x1:roi_x2]

                    if finger_depth_roi.size > 0:
                        finger_z = np.median(finger_depth_roi)  # ì†ê°€ë½ ê¹Šì´ (ì¤‘ì•™ê°’)

                        # ì¢…ì´(ë°”ë‹¥) ê¹Šì´ëŠ” ë³´í†µ ê°€ì¥ ë¨¼ ê°’(0ì— ê°€ê¹Œì›€)ì´ê±°ë‚˜
                        # í˜„ì¬ ROI ì£¼ë³€ë¶€ì˜ ìµœì†Œê°’ìœ¼ë¡œ ì¶”ì • ê°€ëŠ¥
                        # ì—¬ê¸°ì„œëŠ” ê°„ë‹¨íˆ í™”ë©´ ì „ì²´ì˜ í•˜ìœ„ 10% ê°’ì„ ë°”ë‹¥ìœ¼ë¡œ ê°€ì • (ë˜ëŠ” ê³ ì •ê°’)
                        paper_z = 0.2  # ì˜ˆì‹œ ê¸°ì¤€ê°’ (ìƒí™©ì— ë”°ë¼ 0.0~0.2 ì‚¬ì´)

                        # DA3: ê°€ê¹Œìš¸ìˆ˜ë¡ ê°’ í¼(1.0), ë©€ìˆ˜ë¡ ê°’ ì‘ìŒ(0.0)
                        # ì†ê°€ë½ì´ ë–  ìˆìŒ -> finger_zê°€ í¼ (ì˜ˆ: 0.8)
                        # ì†ê°€ë½ì´ ë‹¿ìŒ   -> finger_zê°€ ì‘ì•„ì§ (paper_zì™€ ë¹„ìŠ·í•´ì§)

                        # ë†’ì´ ì°¨ì´ (í´ìˆ˜ë¡ ë–  ìˆëŠ” ê²ƒ)
                        diff = finger_z - paper_z

                        # ìƒíƒœ íŒì •
                        if diff < TOUCH_THRESHOLD:
                            status = "TOUCH!"
                            color = (0, 255, 0)  # ì´ˆë¡ (ì…ë ¥)
                        else:
                            status = "Hover"
                            color = (0, 0, 255)  # ë¹¨ê°• (ëœ¸)

                        # ê°€ìƒ í™”ë©´ì— í‘œì‹œ
                        cv2.circle(warped_view, (tx, ty), 10, color, -1)
                        cv2.putText(warped_view, f"{status} ({diff:.2f})", (tx + 15, ty),
                                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)

    # 4. í™”ë©´ ì¶œë ¥
    cv2.imshow("Original Camera", frame)
    if warped_view is not None:
        # ê¹Šì´ë§µë„ ê°™ì´ ë³´ê¸° (ë””ë²„ê¹…ìš©)
        depth_vis = (depth_norm * 255).astype(np.uint8)
        depth_vis = cv2.applyColorMap(depth_vis, cv2.COLORMAP_INFERNO)

        # ê°€ìƒ í™”ë©´ + ê¹Šì´ë§µ ë‚˜ë€íˆ ì¶œë ¥
        h, w = warped_view.shape[:2]
        depth_vis_resized = cv2.resize(depth_vis, (w, h))
        combined = np.hstack((warped_view, depth_vis_resized))

        cv2.imshow("Warped View & Depth", combined)

    if cv2.waitKey(1) & 0xFF == ord('q'):
        break

cap.release()
cv2.destroyAllWindows()